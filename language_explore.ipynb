{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/Rui/anaconda/envs/python35/lib/python3.5/site-packages\")\n",
    "# where the packages are located\n",
    "import os, shutil, gensim, nltk,re\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    \"\"\"Given a string (text) and do 1: tokenize on spaces (remove punctuation);\n",
    "    2: remove stop words (including the 2s and 3s that are from transcription);\n",
    "    return the preprocessed text as string.\n",
    "    \"\"\"\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+') # define the tokenizer\n",
    "\n",
    "    stopset = set(nltk.corpus.stopwords.words('english')).union(set(['2s', '3s',\n",
    "                                                                 'um', 'yeah', 'incomprehensible',\n",
    "                                                                     'incomprehesible',\n",
    "                                                                     'incomprehensibe',\n",
    "                                                                     'demantor',\n",
    "                                                                     'laughter'])) # define set of stop words\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text_ts = [w for w in tokenizer.tokenize(text) if not w in stopset]\n",
    "    return(text_ts)\n",
    "\n",
    "def text2tfDict(text):\n",
    "    \"\"\"Given a string and turn it to tf dictionary.i.e.\n",
    "    'cigarette store need cigarette' -> {'need':0.25, 'cigarette': 0.5, 'store': 0.25}\n",
    "    \"\"\"\n",
    "    tf_dict = dict()\n",
    "    for key, value in Counter(text).items():\n",
    "        tf_dict[key] = value/len(Counter(text))\n",
    "        \n",
    "    return(Counter(text))\n",
    "\n",
    "def tfDict2vec(tf_dict):\n",
    "    \"\"\"Given a tf dictionary and calculate the weighted sum vector. shape (300,)\n",
    "    return a vector named textVec\n",
    "    \"\"\"\n",
    "    textVec = np.zeros((300,))\n",
    "    for key, value in tf_dict.items():\n",
    "        textVec = textVec + model[key] * value\n",
    "    return(textVec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# here we import the language model (may take a while)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:70: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 2)\n",
      "(0, 3)\n",
      "(0, 4)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(1, 4)\n",
      "(2, 3)\n",
      "(2, 4)\n",
      "(3, 4)\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:94: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:95: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/Rui/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:122: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    os.chdir(\"/Users/Rui/Box Sync/PSAs/05_Analyses/Rui/language_similarity/\")\n",
    "    data_dir = \"/Users/Rui/Box Sync/PSAs/03_Data/02_psa_transcripts/transcripts/txt\"\n",
    "\n",
    "    subjs = ['PSA005', 'PSA007', 'PSA009', 'PSA010', 'PSA016', 'PSA017', 'PSA019',\n",
    "         'PSA026', 'PSA027', 'PSA028', 'PSA029', 'PSA030', 'PSA032', 'PSA036',\n",
    "         'PSA038', 'PSA056', 'PSA061', 'PSA068', 'PSA069', 'PSA078', 'PSA079',\n",
    "         'PSA086', 'PSA094', 'PSA108', 'PSA109', 'PSA112', 'PSA119', 'PSA120',\n",
    "         'PSA127', 'PSA128', 'PSA131', 'PSA132', 'PSA142','PSA144', 'PSA153',\n",
    "         'PSA154', 'PSA156'] #37 subjs\n",
    "    \n",
    "    test_num = 5\n",
    "\n",
    "    # create a dataframe\n",
    "    df = pd.DataFrame(np.nan, index = range(15904), columns = ['subj1', 'vID1', 'subj2', 'vID2',\n",
    "                   'language_sim', 'txt1','txt2'])\n",
    "    rownum = 0\n",
    "    for i in list(itertools.combinations(range(test_num),2)):\n",
    "        print(i)\n",
    "        # two different participants talking about different ads\n",
    "        for j in list(itertools.combinations(range(12),2)):\n",
    "            df['subj1'][rownum] = subjs[i[0]]\n",
    "            df['vID1'][rownum] = j[0] + 1\n",
    "            df['subj2'][rownum] = subjs[i[1]]\n",
    "            df['vID2'][rownum] = j[1] + 1\n",
    "\n",
    "            # read in two texts to compare\n",
    "            f1_open = open(os.path.join(data_dir, subjs[i[0]] + \"_\" + str(j[0] + 1) + \".txt\"), 'rb')\n",
    "            txt1 = f1_open.read().decode('utf8', 'ignore')\n",
    "            f1_open.close()\n",
    "\n",
    "            f2_open = open(os.path.join(data_dir, subjs[i[1]] + \"_\" + str(j[1] + 1) + \".txt\"), 'rb')\n",
    "            txt2 = f2_open.read().decode('utf8', 'ignore')\n",
    "            f2_open.close()\n",
    "\n",
    "            df['txt1'][rownum] = txt1\n",
    "            df['txt2'][rownum] = txt2\n",
    "\n",
    "            # get the vec for txt1\n",
    "            txt1_ts = preprocess(txt1)\n",
    "            txt1_tf = text2tfDict(txt1_ts)\n",
    "            txt1_vec = tfDict2vec(txt1_tf)\n",
    "\n",
    "            # get the vec for txt2\n",
    "            txt2_ts = preprocess(txt2)\n",
    "            txt2_tf = text2tfDict(txt2_ts)\n",
    "            txt2_vec = tfDict2vec(txt2_tf)\n",
    "\n",
    "            # calculate the euclidian distance between two vectors\n",
    "\n",
    "            df['language_sim'][rownum] = np.corrcoef(txt1_vec, txt2_vec)[0,1]\n",
    "\n",
    "            rownum += 1\n",
    "        # two different participants talking about the same ads\n",
    "        for k in range(12):\n",
    "            df['subj1'][rownum] = subjs[i[0]]\n",
    "            df['vID1'][rownum] = k + 1\n",
    "            df['subj2'][rownum] = subjs[i[1]]\n",
    "            df['vID2'][rownum] = k + 1\n",
    "\n",
    "            # read in two texts to compare\n",
    "            f1_open = open(os.path.join(data_dir, subjs[i[0]] + \"_\" + str(k + 1) + \".txt\"), 'rb')\n",
    "            txt1 = f1_open.read().decode('utf8', 'ignore')\n",
    "            f1_open.close()\n",
    "\n",
    "            f2_open = open(os.path.join(data_dir, subjs[i[1]] + \"_\" + str(k + 1) + \".txt\"), 'rb')\n",
    "            txt2 = f2_open.read().decode('utf8', 'ignore')\n",
    "            f2_open.close()\n",
    "\n",
    "            df['txt1'][rownum] = txt1\n",
    "            df['txt2'][rownum] = txt2\n",
    "\n",
    "            # get the vec for txt1\n",
    "            txt1_ts = preprocess(txt1)\n",
    "            txt1_tf = text2tfDict(txt1_ts)\n",
    "            txt1_vec = tfDict2vec(txt1_tf)\n",
    "\n",
    "            # get the vec for txt2\n",
    "            txt2_ts = preprocess(txt2)\n",
    "            txt2_tf = text2tfDict(txt2_ts)\n",
    "            txt2_vec = tfDict2vec(txt2_tf)\n",
    "\n",
    "            # calculate the euclidian distance between two vectors\n",
    "\n",
    "            df['language_sim'][rownum] = np.corrcoef(txt1_vec, txt2_vec)[0,1]\n",
    "\n",
    "            rownum += 1\n",
    "            \n",
    "    # same participant talking about different ads\n",
    "    for i in range(test_num):\n",
    "        print(i)\n",
    "        for j in list(itertools.combinations(range(12),2)):\n",
    "            df['subj1'][rownum] = subjs[i]\n",
    "            df['vID1'][rownum] = j[0] + 1\n",
    "            df['subj2'][rownum] = subjs[i]\n",
    "            df['vID2'][rownum] = j[1] + 1\n",
    "\n",
    "            # read in two texts to compare\n",
    "            f1_open = open(os.path.join(data_dir, subjs[i] + \"_\" + str(j[0] + 1) + \".txt\"), 'rb')\n",
    "            txt1 = f1_open.read().decode('utf8', 'ignore')\n",
    "            f1_open.close()\n",
    "\n",
    "            f2_open = open(os.path.join(data_dir, subjs[i] + \"_\" + str(j[1] + 1) + \".txt\"), 'rb')\n",
    "            txt2 = f2_open.read().decode('utf8', 'ignore')\n",
    "            f2_open.close()\n",
    "\n",
    "            df['txt1'][rownum] = txt1\n",
    "            df['txt2'][rownum] = txt2\n",
    "\n",
    "            # get the vec for txt1\n",
    "            txt1_ts = preprocess(txt1)\n",
    "            txt1_tf = text2tfDict(txt1_ts)\n",
    "            txt1_vec = tfDict2vec(txt1_tf)\n",
    "\n",
    "            # get the vec for txt2\n",
    "            txt2_ts = preprocess(txt2)\n",
    "            txt2_tf = text2tfDict(txt2_ts)\n",
    "            txt2_vec = tfDict2vec(txt2_tf)\n",
    "\n",
    "            # calculate the euclidian distance between two vectors\n",
    "\n",
    "            df['language_sim'][rownum] = np.corrcoef(txt1_vec, txt2_vec)[0,1]\n",
    "\n",
    "            rownum += 1\n",
    "            \n",
    "        \n",
    "\n",
    "df.to_csv(\"/Users/Rui/Desktop/language_dis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    os.chdir(\"/Users/Rui/Box Sync/PSAs/05_Analyses/Rui/language_similarity/\")\n",
    "    data_dir = \"/Users/Rui/Box Sync/PSAs/03_Data/02_psa_transcripts/transcripts/txt\"\n",
    "\n",
    "    subjs = ['PSA005', 'PSA007', 'PSA009', 'PSA010', 'PSA016', 'PSA017', 'PSA019',\n",
    "         'PSA026', 'PSA027', 'PSA028', 'PSA029', 'PSA030', 'PSA032', 'PSA036',\n",
    "         'PSA038', 'PSA056', 'PSA061', 'PSA068', 'PSA069', 'PSA078', 'PSA079',\n",
    "         'PSA086', 'PSA094', 'PSA108', 'PSA109', 'PSA112', 'PSA119', 'PSA120',\n",
    "         'PSA127', 'PSA128', 'PSA131', 'PSA132', 'PSA142','PSA144', 'PSA153',\n",
    "         'PSA154', 'PSA156'] #37 subjs\n",
    "\n",
    "    # create a dataframe\n",
    "    #df = pd.DataFrame(np.nan, index = range(7992), columns = ['subj1', 'subj2', 'vID',\n",
    "    #               'language_dis'])\n",
    "    #rownum = 0\n",
    "    #for i in list(itertools.combinations(range(37),2)):\n",
    "    #    for j in range(12):\n",
    "    #        print(rownum)\n",
    "    #        df['subj1'][rownum] = i[0]\n",
    "    #        df['subj2'][rownum] = i[1]\n",
    "    #        df['vID'][rownum] = j + 1\n",
    "\n",
    "            # read in two texts to compare\n",
    "    for i in (range(12)):\n",
    "        f1_open = open(os.path.join(data_dir, subjs[1] + \"_\" + str(1) + \".txt\"), 'rb')\n",
    "        txt1 = f1_open.read().decode('utf8', 'ignore')\n",
    "        f1_open.close()\n",
    "\n",
    "        f2_open = open(os.path.join(data_dir, subjs[1] + \"_\" + str(i + 1) + \".txt\"), 'rb')\n",
    "        txt2 = f2_open.read().decode('utf8', 'ignore')\n",
    "        f2_open.close()\n",
    "\n",
    "        # get the vec for txt1\n",
    "        txt1_ts = preprocess(txt1)\n",
    "        txt1_tf = text2tfDict(txt1_ts)\n",
    "        txt1_vec = tfDict2vec(txt1_tf)\n",
    "\n",
    "        # get the vec for txt2\n",
    "        txt2_ts = preprocess(txt2)\n",
    "        txt2_tf = text2tfDict(txt2_ts)\n",
    "        txt2_vec = tfDict2vec(txt2_tf)\n",
    "\n",
    "        print(txt1)\n",
    "        print(i + 1)\n",
    "        print(txt2)\n",
    "\n",
    "\n",
    "        plt.plot(txt1_vec)\n",
    "        plt.plot(txt2_vec)\n",
    "        plt.ylabel('word2vec')\n",
    "        plt.show()\n",
    "\n",
    "        print(np.corrcoef(txt1_vec, txt2_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
